\documentclass[12pt]{article}

\usepackage[italian]{babel}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{listings}

\geometry{margin=2cm}

\newcounter{questioncounter}
\newcommand{\question}[1]{
    \stepcounter{questioncounter}
    \textbf{\\\textcolor{red}{\arabic{questioncounter}. #1}}\\
}

\let\olditemize\itemize
\renewcommand\itemize{\olditemize\setlength\itemsep{0em}}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}


\title{Domande Orale Primo Modulo}
\author{}
\date{}

\begin{document}
\maketitle
Domande per l'orale del primo modulo di Analisi e Progettazione di Algoritmi (APA).
\question{Complessità di problemi, problemi aperti e chiusi}
Un problema può avere complessità $O(f(n)), \Omega(f(n)) \text{ o } \Theta(f(n))$. Solitamente $O$ è per indicare il caso peggiore (quindi il limite superiore), $\Omega$ per il caso migliore (quindi il limite inferiore) e $\Theta$ quando si conoscono il limite inferiore e superiore.
Nel caso di algoritmi randomizzati si calcola la media pesata di tutti i tempi di esecuzione per uno stesso input e quello che interessa è il caso peggiore, quindi quello con tempo di esecuzione maggiore.\\
Un problema si dice \textbf{chiuso} quando esiste un algoritmo di complessità $O(f(n))$ e si è dimostrato che qualunque algoritmo risolvente ha complessità $\Omega(f(n))$, ossia non può esistere un algoritmo di complessità inferiore a $\Omega(f(n))$ (in altre parole $O(f(n)) = \Omega(f(n))$), dimostrando così che l'algoritmo è \textbf{ottimo} con possibili miglioramenti marginali.\\ Un problema si dice \textbf{aperto} quando il miglior algoritmo risolvente noto è $O(f(n))$ e si è dimostrato che qualunque algoritmo risolvente deve avere complessità $\Omega(g(n))$ con $g \neq f$. In altri termini, si sa risolvere il problema in un tempo $f(n)$ e si sa che non lo si può risolvere in un tempo migliore $g(n)$, dove $g$ 'cresce meno' di $f$ (in altre parole $O(f(n)) \neq \Omega(g(n))$).\\
Un problema potrebbe avere anche un \textbf{gap algoritmico} che può essere chiuso 'dal di sopra' trovando un algoritmo migliore che, se coincide con il limite inferiore, rende l'algoritmo chiuso e ottimo oppure 'dal di sotto' dimostrando che esiste un limite inferiore più alto, similmente a prima se questo coincide con il limite superiore l'algoritmo è chiuso e ottimo.
\question{Algoritmo di Dijkstra}
Problema: dato un grafo orientato pesato $G$, con pesi non negativi e dati un nodo di partenza $s$ e un nodo di arrivo $t$, trovare un cammino minimo tra $s$ e $t$.
\begin{lstlisting}[language=C]
    Dijkstra(G,s)
        for each (u nodo in G) dist[u] = +inf
        parent[s] = null; dist[s] = 0
        Q = heap vuoto
        for each (u nodo in G) Q.add(u,dist[u])
        while(Q non vuota)
            u = Q.getMin() // nodo u nero
            for each((u,v) arco in G)
                if dist[u] + peso(u,v) < dist[v]
                    dist[v] = dist[u] + peso(u,v); parent[v] = u
                    Q.changePriority(v,dist[v])
        return dist, parent
\end{lstlisting}
A parole: si inizializzano i pesi dei nodi a $\infty$ tranne che per il nodo di partenza che si inizializza a 0. Si crea un heap con i nodi e i loro pesi e, fino a quando l'heap non è vuoto, si estrae il nodo grigio con peso minore e si marca come visitato (nero). Per ogni arco uscente dal nodo si controlla se il peso del nodo di partenza più il peso dell'arco è minore del peso "registrato" nell'heap, in tal caso si aggiorna il peso e si cambia la priorità nell'heap e si marca il nodo $v$ come grigio.\\
\textbf{NB}: in un heap il padre ha priorità minore dei figli, quindi il nodo con peso minore è in cima all'heap.\\
\textbf{Complessità:}
\begin{itemize}
    \item Inizializzazione nodi bianchi: $O(n)$
    \item $n$ estrazioni da heap: $O(n \log n)$
    \item ciclo interno dove ogni arco viene percorso una volta e per ogni nodo adiacente si ha eventuale cambio di priorità: $O(m\log n)$
\end{itemize}
Complessivamente $O(n \log n + m \log n)=O((n+m)\log n)$, nel caso di grafo denso $m=n^{2} \rightarrow O(n^{2}\log n)$
\question{Definizione di minimo albero ricoprente, algoritmi di Prim e Kruskal}
Un \textbf{minimo albero ricoprente} di $G$ è un albero ricoprente (che contiene tutti i nodi del grafo ed è aciclico) di $G$ in cui la somma degli archi è minima.
\begin{lstlisting}[language=C]
    Prim(G,s)
        for each (u nodo in G) marca u come non visitato
        for each (u nodo in G) dist[u] = inf
        parent[s] = null ; dist[s] = 0
        Q = heap vuoto
        for each (u nodo in G) Q.add(u,dist[u])
        while (Q non vuoto)
            u = Q.getMin()
            marca u come visitato (nero)
            for each((u,v) arco in G)
                if v non visitato e peso(u,v) < dist[v]
                    dist[v] = peso(u,v); parent[v] = u
                    Q.changePriority(v,dist[v])
\end{lstlisting}
\textbf{Complessità:} uguale a Dijkstra, $O((n+m)\log n)$
\begin{lstlisting}[language=C]
    Kruskal(G)
        s = sequenza di archi di G in ordine di costo crescente
        T = foresta formata dai nodi di G e nessun arco
        counter = 0
        while(counter < n-1)
            estrai da s il primo elemento (u,v)
            if (u,v non connessi in T) T = T + (u,v) // aggiungi arco
            counter++
        return T
\end{lstlisting}
\textbf{Complessità:} il problema è controllare se due nodi sono già connessi. Farlo in modo banale con una visita dei due alberi richiede $O(n)$ nel caso peggiore, quindi si ha $O(n\cdot m)$.
\begin{lstlisting}[language=C]
    KruskalUF(G)
        s = sequenza di archi di G in ordine di costo crescente
        T = foresta formata dai nodi di G e nessun arco
        UF = struttura union-find vuota
        for each (u nodo in G) UF.makeSet(u)
        while (s non vuota)
            estrai da s il primo elemento (u,v)
            if(UF.union_by_need(u,v)) 
            // esegue la union delle radici se UF.find(u) != UF.find(v)
                T = T + (u,v)
        return T
\end{lstlisting}
\textbf{Complessità:} $O(m\log m)$
\question{Definizione di ordinamento topologico, i due algoritmi per calcolarlo}
Un ordinamento topologico di un grafo orientato aciclico (DAG) $G=(V,E)$ è un ordine totale stretto su $V$ tale che se $(u,v) \in E$ allora $u$ precede $v$ nell'ordinamento ($u<v$).
\begin{lstlisting}[language=C]
    topologicalsort(G)
        S = insieme vuoto
        Ord = sequenza vuota
        for each (u nodo in G) indegree[u] = indegree di u
        for each (u nodo in G)
            if indegree[u] == 0 S.add(u)
        while (S non vuoto)
            u = S.remove()
            Ord.add(u) // in fondo
            for each ((u,v) arco in G)
                indegree[v]--
                if indegree[v] == 0 S.add(v)
        return Ord
\end{lstlisting}
\textbf{Complessità:} $O(n+m)$
\begin{lstlisting}[language=C]
    DFS(G)
        for each (u nodo in G) marca u come bianco ; parent[u] = null
        time = 0
        for each (u nodo in G)
            if u bianco DFS-Visit(G,u)

    DFS-Visit(G,u,T)
        time++; start[u] = time
        visita u ; marca u come grigio
        for each ((u,v) arco in G)
            if v bianco
                parent[v] = u
                DFS-Visit(G,v)
        time++; end[u] = time
\end{lstlisting}
\textbf{Complessità:} $O(n+m)$
\question{Definizione di componenti fortemente connesse, l'algoritmo per calcolarle}
In un grafo orientato $G$, due nodi $u$ e $v$ si dicono mutualmente raggiungibili, o \textbf{fortemente connessi}, se ognuno dei due è raggiungibile dall'altro, ossia se esistono un cammino da $u$ a $v$ e un cammino da $v$ a $u$. Una \textbf{componente fortemente connessa} è un sottografo di $G$ in cui i nodi sono tutti fortemente connessi tra loro.
\begin{lstlisting}[language=C]
    SCC(G)
        DFS(G, Ord)
        GT = grafo trasposto di G
        OrdFC = sequenza vuota // componenti fortemente connesse
        while(Ord non vuota)
            u = ultimo nodo visitato in Ord
            C = insieme di nodi vuoto
            DFS(GT,u,C)
            OrdFC.add(C)
        return OrdFC    
\end{lstlisting}
\textbf{Complessità:} $O(n+m)$
\begin{lstlisting}[language=C]
    CFC(G)
        Ord = DFS(G) // con i time-stamp (solo questa)
        GT = grafo trasposto di G
        OrdFC = sequenza vuota // componenti fortemente connesse
        while(Ord non vuota)
            u = primo nodo non visitato in Ord
            C = DFS(GT,u)
            OrdFC.add(C)
        return OrdFC    
\end{lstlisting}
\question{Caratteristiche della programmazione dinamica, problema LCS e algoritmo per risolverlo, algoritmo di Floyd-Warshall}
La programmazione dinamica è vantaggiosa se un sottoproblema viene usato più volte, si basa su def. ricorsiva come divide-et-impera e la correttezza per induzione forte, spesso bottom-up (memorizzazione dei risultati dei sottoproblemi).\\
LCS problema: date due sequenze trovare una sottosequenza comune di lunghezza massima.\\
Si costruisce una matrice LCS con m+1 righe e n+1 colonne. La prima riga e la prima colonna sono inizializzate a 0. Si può procedere riga per riga o colonna per colonna, l'ultima casella (angolo in basso a destra) conterrà la soluzione. Se si ha lo stesso carattere sulla riga e sulla colonna, una "freccia diagonale", aumentando di 1 la lunghezza rispetto alla casella puntata dalla freccia; se sulla riga e sulla colonna ci sono due caratteri diversi, una freccia verso la casella con il valore maggiore tra la casella sopra e la casella a sinistra (se i valori sono uguali punto sempre sopra). Per l'algoritmo abbiamo la matrice L per le lunghezze e la matrice R dei riferimenti, X e Y sono le sequenze.
\begin{lstlisting}[language=C]
    LCS(L,R,X,Y)
        for(i=0;i<=m;i++) L[i][0] = 0
        for(j=0;j<=n;j++) L[0][j] = 0

        for(i=1;i<=m;i++)
            for(j=1;j<=n;j++)
                if(X[i]==Y[j])
                    L[i,j] = L[i-1,j-1] + 1
                    R[i,j] = "diagonale"
                else if(L[i-1,j] > L[i,j-1])
                    L[i,j] = L[i,j-1]
                    R[i,j] = "sinistra"
                else
                    L[i,j] = L[i-1,j]
                    R[i,j] = "sopra"
\end{lstlisting}
In corrispondenza di ogni freccia diagonale abbiamo un elemento della sottosequenza comune.\\
\textbf{Complessità:} $\Theta(mn)$.\\
Problema: dato un grafo pesato $G$ trovare il cammino minimo tra ogni coppia di nodi. Sono ammessi costi negativi ma non cicli di costo negativo.\\
Idea: chiamiamo k-vincolato un cammino che passa solo per nodi $1\ldots k$ (esclusi gli estremi), per $k\leq n$, e indichiamo con $d^{k}(x,y)$ la distanza k-vincolata tra $x$ e $y$, cioè la lunghezza minima di un cammino k-vincolato.
\begin{lstlisting}[language=C]
    Floyd-Warshall(G)
        for each (x,y nodi in G)
            D[x,y] = 0 se x=y, peso(x,y) se x!=y, +inf altrimenti
            P[x,y] = x se x!=y e (x,y) in E, null altrimenti
        for (k=1;k<=n;k++)
            for (x,y nodi in G)
                if (D[x,k]+D[k,y]<D[x,y])
                    D[x,y] = D[x,k]+D[k,y]
                    P[x,y] = P[k,y]
        return D,P
\end{lstlisting}
\textbf{Complessità:} $O(n^{3})$
\question{Definizioni di problema di decisione, astratto e concreto, algoritmo di verifica, classi P, NP e NP-C}
\question{Nozione di riduzione polinomiale, definizione di classe NP-C, problema P-NP}
\question{Esempi di problemi NP-completi e riduzioni (SAT, 3SAT, CLIQUE)}
\end{document}